# Desafio Backend RAG â€” Sistema de Busca SemÃ¢ntica e Q&A

Bem-vindo(a)! Este Ã© um **teste prÃ¡tico** para a vaga de **AI Developer** na **Jungle Gaming**. O objetivo Ã© avaliar sua capacidade de construir um sistema de Retrieval-Augmented Generation para processar documentos PDF e responder perguntas.

> **Stack Recomendada**
>
> * **Backend:** Python (FastAPI) ou Node.js (Express/Fastify)
> * **Vector Database:** Sua escolha (ChromaDB, Qdrant, Pinecone, Weaviate, etc.)
> * **Embeddings:** Sua escolha (OpenAI, Cohere, HuggingFace, etc.)
> * **LLM:** Sua escolha (OpenAI, Anthropic, Cohere, Ollama, etc.)
> * **Processamento:** LangChain, LlamaIndex ou implementaÃ§Ã£o prÃ³pria
> * **Infra:** Docker & docker-compose

---

## ğŸ¯ Contexto & Objetivo

Construir uma **API REST de RAG** que processe documentos PDF, faÃ§a indexaÃ§Ã£o vetorial, e responda perguntas usando retrieval-augmented generation. O sistema deve retornar respostas contextualizadas com **mÃ©tricas de confianÃ§a**.

**O que queremos observar:**

* Pipeline de processamento e chunking de PDFs
* Qualidade do retrieval (busca semÃ¢ntica)
* Prompt engineering e chain design
* Estrutura e organizaÃ§Ã£o do cÃ³digo
* DocumentaÃ§Ã£o da API

---

## ğŸ§± Requisitos Funcionais

### 1. IngestÃ£o de Documentos PDF

* **Upload** de arquivos PDF via API
* **ExtraÃ§Ã£o** de texto do PDF
* **Chunking inteligente:**
  * Chunks de tamanho configurÃ¡vel (sugestÃ£o: 500 caracteres)
  * Overlap configurÃ¡vel
  * Metadata: filename, chunk_index, timestamp
* **GeraÃ§Ã£o de embeddings** e armazenamento no vector store
* **Resposta com ID do documento** e estatÃ­sticas

### 2. Busca e Q&A

* **Endpoint de query** que recebe uma pergunta
* **Busca semÃ¢ntica** nos chunks (top-k configurÃ¡vel)
* **GeraÃ§Ã£o de resposta** usando LLM com contexto
* **Resposta estruturada** contendo:
  * Texto da resposta
  * Confidence score
  * Tokens utilizados (opcional)

### 3. Gerenciamento

* **Listar documentos** processados
* **Health check** do sistema

---

## âš¡ API Endpoints (ObrigatÃ³rios)

```http
POST   /api/documents/upload       # Upload de PDF
GET    /api/documents              # Lista documentos

POST   /api/query                  # Pergunta ao sistema

GET    /api/health                 # Status dos componentes
```

### Exemplos de Request/Response

#### Upload de PDF
```bash
POST /api/documents/upload
Content-Type: multipart/form-data

Response:
{
  "document_id": "01998714-4d0d-7620-a18b-5ac0cb775ac1",
  "filename": "manual.pdf",
  "chunks_created": 45
}
```

#### Query RAG
```bash
POST /api/query
{
  "question": "Como configurar o banco de dados?",
  "top_k": 3
}

Response:
{
  "answer": "Para configurar o banco de dados, vocÃª deve...",
  "confidence": 0.85,
  "processing_time": 1.2
}
```

---

## ğŸ—ï¸ Estrutura Sugerida

```
.
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/              # Endpoints
â”‚   â”œâ”€â”€ services/         # LÃ³gica de negÃ³cio
â”‚   â”‚   â”œâ”€â”€ pdf_processor.py
â”‚   â”‚   â”œâ”€â”€ embeddings.py
â”‚   â”‚   â””â”€â”€ rag_chain.py
â”‚   â”œâ”€â”€ config.py
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt / package.json
â”œâ”€â”€ .env.example
â””â”€â”€ README.md
```

---

## ğŸ“‹ Requisitos TÃ©cnicos

### PDF Processing
* **ExtraÃ§Ã£o de texto** do PDF
* **Chunking** que nÃ£o quebre frases no meio
* **Processamento eficiente** de documentos

### Embeddings
* Modelo de sua escolha
* Justifique a escolha no README

### Retrieval
* **Similarity search** 
* **Filtros** por documento quando especificado

### LLM Integration
* **Prompt template** bem estruturado
* **System prompt** instruindo uso de contexto
* **Handling** quando nÃ£o hÃ¡ contexto relevante

---

## ğŸ“ CritÃ©rios de AvaliaÃ§Ã£o

### ObrigatÃ³rio
- [ ] API funcional com todos endpoints
- [ ] Upload e processamento de PDF
- [ ] Busca semÃ¢ntica funcionando
- [ ] Respostas contextualizadas baseadas nos documentos
- [ ] Docker Compose configurado

### Qualidade
- [ ] Chunking inteligente
- [ ] Prompt engineering eficaz
- [ ] CÃ³digo limpo e organizado
- [ ] Error handling adequado

### Diferencial
- [ ] Testes automatizados
- [ ] Cache de embeddings
- [ ] DocumentaÃ§Ã£o OpenAPI/Swagger
- [ ] MÃ©tricas de qualidade do retrieval

---

## ğŸ§ª Teste

Inclua um PDF de exemplo no repositÃ³rio e algumas queries de teste:

```json
{
  "test_queries": [
    {
      "query": "Pergunta sobre conteÃºdo especÃ­fico do PDF",
      "expected_keywords": ["palavra1", "palavra2"]
    }
  ]
}
```

---

## ğŸ“š DocumentaÃ§Ã£o Esperada

No README do projeto:

1. **Arquitetura** do sistema
2. **Justificativa** das escolhas tÃ©cnicas (modelos, chunk size, etc.)
3. **Como rodar** (Docker)
4. **Exemplos de uso** (cURL/Postman)
5. **LimitaÃ§Ãµes e melhorias futuras**

---

## ğŸ’¡ Dicas

* **Comece simples:** Upload â†’ Chunking â†’ Embeddings â†’ Query
* **PDFs pequenos** para testes iniciais (5-10 pÃ¡ginas)
* **Foque na qualidade** das respostas geradas
* **Documente suas decisÃµes** tÃ©cnicas

---

## ğŸ“§ Suporte e DÃºvidas

Caso tenha alguma dÃºvida sobre o teste ou precise de esclarecimentos:

* Entre em contato com o **recrutador que enviou este teste**
* Ou envie um e-mail para: **recruitment@junglegaming.io**

Responderemos o mais breve possÃ­vel para garantir que vocÃª tenha todas as informaÃ§Ãµes necessÃ¡rias para realizar o desafio.

---

## ğŸ•’ Prazo

* **Entrega:** 14 dias corridos
* **Formato:** RepositÃ³rio Git com README completo

**Boa sorte!** ğŸš€
